TODO

-Add rerequest feature.

-Add a stop function to the server to stop the server thread. Make it so servers
can be properly created and destroyed.

-Add a client_buffer feature to allow download to check for errors.


BUGS

-Resumed downloading is broken. Files truncated on resume.


DEFERRED FEATURES

-Needs to be a check so that when the user tries to download the same thing
twice the second download doesn't get appended to the first. Make a database
to store downloaded file information to check against.


IDEAS

-File location should be done with trackers which are organized in to a tree
structure such that if the user adds a tracker the user will also get to see
the files of the trackers that tracker trusts and the files that that tracker
trusts etc. Have an option to limit trust levels to direct trust only, one
level inheritance and all level inheritance.


-Keep track of the current download speed from a server by timestamping download_file_conn
whenever latest_request is updated (and later calculating speed in response). From
this time target new requests such that the requests line up with the expected
progress of the file download. This is an attempt to somehow put servers operating
at different speeds on equal footing algorithmically. I don't want a hard limit
for buffer size that kills slow servers when a fast server is connected. I want
to target requests such that slow server can still participate in the download.


PORTABILITY SNAGS

-Paths have forward slashes in them in globals.h
