BUGS AND NECESSARY FEATURES

-Make client::infoBuffer store IP's in a vector. Correctly download IP display
in the gui.

-Program crashes if trying to resume download where the user has removed the partial
file.

-The client doesn't need to know what fileID it requested a block from.

-There is no check for a download already completed by the download feature.

-If the download directory is missing and a download is started the directory
is not created and the RAM starts getting sucked up because nothing is getting
written to disk.

-There should be a check for the delimiter in the index files.
Filenames can have a delimiter in them and mess things up.

-Client has no control of how many connections it will try to make.


POSSIBLE FEATURES

-Writing to disk is slowing down rerequests and hurting speed.

-Small packet size is wasting a lot of speed. Hypothesis is that the total time 
waiting between request of data and data transmission is greater the smaller
the packet size. 4096 = 1000kB/s vs 65535 = 2200kB/s.

-Add a check to make sure the client is not requesting the same blocks over
and over(trying to waste bandwidth to degrate serving capability).

-Have the serverIndex poll to check for new files added to share.

-Come up with a indexing scheme for search.db(it'll get big).

-Reduce control data size by encoding file and fileBlock numbers. Also, perhaps
negotiate control data size for each download.

-Information in the gui statusbar for protocol overhead.


IDEAS

-Locating files should be done on a tiered linear network. Hosts should connect to
eachother in a sequential way on level 1 but in other ways on the other levels to
make it so the client can start traversing the network on the level which is closest.

Tier 1: Linear
Tier 2: Random

Question: How would tier 1 remain connected at all times?
Question: How to insure roughly the same access time to any node?

